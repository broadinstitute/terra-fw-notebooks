{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing the Tetralogogy of Fallot Cluster Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook overview \n",
    "\n",
    "This notebook demonstrates the cluster analysis described by Matthieu Miossec and collaborators in the bioRxiv preprint \"[Deleterious genetic variants in NOTCH1 are a major contributor to the incidence of non-syndromic Tetralogy of Fallot (ToF)](https://www.biorxiv.org/content/early/2018/04/13/300905). We reproduced the original analysis in R code in a notebook by working with Dr. Miossec. \n",
    "\n",
    "The notebook walks users through the steps of performing the cluster analysis on two precomputed sets of synthetic data, one with 100 samples, one with 500. The two cluster analyses demonstrate how the larger cohort (comparable to the 829 cohort in the original publication) reproduces Miossec et al.'s published results. \n",
    "\n",
    "## Reprodicibility overview  \n",
    "\n",
    "This notebook is intended as an example of how to make a reproducible study by doing the analysis in an interactive and shareable Jupyter Notebook. Code cells contain the exact R code adapted for reproducing the analysis and each analysis step is documented with accompanying markdown text to explain the researcher's reasoning and methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis description\n",
    "\n",
    "Given a large set of cases, variants contributing to a disease trait will form detectable clusters within specific regions of a gene or genes which, when mutated, lead to the disease. We can uncover these clusters using the WD statistic and reliable sequencing data.\n",
    "\n",
    "For each gene coding sequence (CDS), we enter the number of hits that fall within the CDS and calculate the probability of a single hit falling within this particular CDS given the exome's total CDS size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis steps\n",
    "\n",
    "* Classify nonsense and frameshift mutations\n",
    "* Filter based on CADD > 20, [Combined Annotation Dependent Depletion (CADD)](https://cadd.gs.washington.edu/) method\n",
    "* Identify likely deleterious variant clusters in patient genes\n",
    "* Generate statistics on gene clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Steps                                      | Input                                           | Output |\n",
    "| -------------------------------------------|-------------------------------------------------|--------|\n",
    "| Filter CADD >20 | gemini_out.txt                 | gemini_filtered     |\n",
    "| Count variants per gene                    |gemini_filtered                                  | variants_per_gene   |\n",
    "| Add genes that have a variant count of 0 or X | variants_per_gene | variants_per_CDS |\n",
    "| Sort and add CDS length as fraction of total CDS length | variants_per_CDS | variants_per_CDS_withsizes\n",
    "| Cluster analysis                           | variants_per_CDS_withsizes | new_data     |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources used in the original analysis\n",
    "\n",
    "* [Combined Annotation Dependent Depletion](https://cadd.gs.washington.edu/) (CADD) [v.1.3](https://cadd.gs.washington.edu/static/ReleaseNotes_CADD_v1.3.pdf)\n",
    "* [GoogleCloudStorageR](https://github.com/cloudyr/googleCloudStorageR) v.0.4.0\n",
    "* [Ensembl 75](http://feb2014.archive.ensembl.org/index.html) provides gene coding sequence sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the notebook environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Google Cloud's R package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "install.packages(\"googleCloudStorageR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a key to access Gemini outputs in the workspace's Google bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key <- Ronaldo::getServiceAccountKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the key and write it to a json file that can be accessed from your local cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileConn<-file(\"/home/jupyter/key.json\")\n",
    "writeLines(key, fileConn)\n",
    "close(fileConn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment variable so that googleCloudStorageR can authenticate itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sys.setenv(\"GCS_AUTH_FILE\" = \"/home/jupyter/key.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(googleCloudStorageR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To see more features:  <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the command `library(help = googleCloudStorageR)` and execute in the code cell (below) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and filter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we read the output from the **6_Predict-variant-effects-GEMINI** WDL and start filtering. \n",
    "\n",
    "We capture likely deleterious and missense variants by first filtering out variants that are not stop mutations or frameshift. Then we weed out the missense variants using a CADD score >=20. What's left are likely deleterious variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This notebook reproduces and compares two analyses: one with a participant set of 100 and a second with a particpant set of 500. Because generating and alalyzing a 500-sample synthetic cohort is computationally expensive and long, the notebook will offer two options:           \n",
    "1. Use precomputed files from `6_predict-variant-effects-GEMINI`    \n",
    "2. Analyzing a pre-computed 500-sample cohort "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze 100-sample synthetic cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read gemini_out.txt from the Google bucket and save it to the local Jupyter cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_get_object(\"gs://firecloud-workshops/181017-ashg18/predicted-effects/Test-cohort-A100.jointcalls.filtered.gemini-predictions.txt\", \n",
    "               saveToDisk = \"/home/jupyter/notebooks/gemini_out.txt\",overwrite= TRUE)\n",
    "\n",
    "gemini_out <- read.table(\"/home/jupyter/notebooks/gemini_out.txt\",sep = \"\\t\", header = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for CADD score >= 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gemini_out$cadd_scaled <- as.numeric(as.character(gemini_out$cadd_scaled))\n",
    "gemini_out$cadd_scaled[is.na(gemini_out$cadd_scaled)] <- 0   \n",
    "\n",
    "# Note that the warning message about \"NAs introduced by coercion\" is expected. The function eliminates \n",
    "# zeros in the data set and doesn't impact the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_filtered <- gemini_out[(gemini_out$biotype==\"protein_coding\")& (gemini_out$cadd_scaled>=20),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read ensemble gene CDS sizes from a file in the Google bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_get_object(\"gs://firecloud-workshops/181017-ashg18/annotation/Ensembl75_gene_CDS_sizes.txt\",\n",
    "               saveToDisk = \"/home/jupyter/notebooks/ENS75.txt\",overwrite= TRUE)\n",
    "CDS_size <- read.table(\"/home/jupyter/notebooks/ENS75.txt\",sep = \"\\t\", header = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of variants per gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_per_gene<-aggregate(x = gemini_filtered$gene, by = list(gene = gemini_filtered$gene), FUN = length)\n",
    "colnames(variants_per_gene) <- c(\"gene\",\"variant_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add genes that have a variant count of zero and remove genes that don't have an incomplete CDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_per_CDS<-rbind.data.frame(variants_per_gene[variants_per_gene$gene %in% CDS_size$gene,], data.frame(gene = setdiff(CDS_size$gene,variants_per_gene$gene), variant_count = 0))                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort and add CDS length as fraction of total CDS length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compare the number of variants we would expect by chance and the number of variants we actually observe. Some genes are so big that they’ll definitely have more of variants than NOTCH1. What’s significant is how many variants a gene has given its size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted <- variants_per_CDS[order(as.character(variants_per_CDS$gene)),]\n",
    "variants_per_CDS_withsizes <- data.frame(sorted,length_proportion=CDS_size$length_proportion)\n",
    "\n",
    "# Print the variants per length\n",
    "variants_per_CDS_withsizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify genes where significantly more variants are observed than expected (Cluster.Test method)\n",
    "\n",
    "The method takes in two arguments: NbrInTarget and TargetProbability:\n",
    "\n",
    "* **NbrInTarget** is derived from our data and consists of a list of the number of variants (or hits) per each CDS\n",
    "\n",
    "* **TargetProbability** is the fraction of the total human coding sequence represented by each gene coding sequence. (i.e. gene CDS size/total CDS size). This information is typically derived from BioMart but we can just provide it directly in a file in the Google bucket.\n",
    "\n",
    "Therefore:\n",
    "* N is the number of genes/gene CDS being tested\n",
    "* TotalHits is the total number of variants\n",
    "* ExpectedHits is the number of variants we expect to see in a gene CDS based on its size\n",
    "\n",
    "The last line applies multiple testing correction to the statistical method (i.e. N tests for N gene CDS).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster.Test <- function(NbrInTarget,TargetProbability){\n",
    "N <- length(NbrInTarget)\n",
    "TotalHits <- sum(NbrInTarget)\n",
    "ExpectedHits <- TotalHits*TargetProbability\n",
    "# N*ppois(NbrInTarget,ExpectedHits,lower=F)\n",
    "1-exp(ppois(NbrInTarget,ExpectedHits,lower=T,log=T)*N)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the output of the Cluster.Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdata <- data.frame(variants_per_CDS_withsizes, cluster.test.result = Cluster.Test(variants_per_CDS_withsizes$variant_count,variants_per_CDS_withsizes$length_proportion))\n",
    "newdata[order(newdata$cluster.test.result),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Variant_counts <- head(newdata[order(newdata$cluster.test.result),],20)\n",
    "Variant_counts$minuslog10p = -log10(Variant_counts$cluster.test.result+1e-100)\n",
    "bars <- barplot(Variant_counts$minuslog10p,names.arg = Variant_counts$gene, las=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that NOTCH1 does harbour an excess of rare, deleterious variants among ToF patients in the clustering analysis. \n",
    "\n",
    "However, the NOTCH1 variants were not the top hit found in the original ToF study. Our hypothesis is that the small cohort test run was statistically underpowered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's repeat the analysis with the 500-sample synthetic cohort to test this hypothesis...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze 500-sample synthetic cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next series of cells repeats the cluster analysis above, this time on data from the 500-sample synthetic cohort (precomputed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read gemini_out.txt from the Google bucket and save it to the local Jupyter cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_get_object(\"gs://firecloud-workshops/181017-ashg18/predicted-effects/Test-cohort-A500.jointcalls.filtered.gemini-predictions.txt\",\n",
    "               saveToDisk = \"/home/jupyter/notebooks/gemini_out.txt\",overwrite= TRUE)\n",
    "gemini_out<-read.table(\"/home/jupyter/notebooks/gemini_out.txt\",sep = \"\\t\", header = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for CADD score >= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gemini_out$cadd_scaled <- as.numeric(as.character(gemini_out$cadd_scaled))\n",
    "gemini_out$cadd_scaled[is.na(gemini_out$cadd_scaled)] <- 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_filtered <- gemini_out[(gemini_out$biotype==\"protein_coding\")& (gemini_out$cadd_scaled>=20),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read ensemble gene CDS sizes from a file in the Google bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_get_object(\"gs://firecloud-workshops/181017-ashg18/annotation/Ensembl75_gene_CDS_sizes.txt\",\n",
    "               saveToDisk = \"/home/jupyter/notebooks/ENS75.txt\",overwrite= TRUE)\n",
    "CDS_size <- read.table(\"/home/jupyter/notebooks/ENS75.txt\",sep = \"\\t\", header = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of variants per gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_per_gene <- aggregate(x = gemini_filtered$gene, by = list(gene = gemini_filtered$gene), FUN = length)\n",
    "colnames(variants_per_gene) <- c(\"gene\",\"variant_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add genes that have a variant count of zero and remove genes that don't have an incomplete CDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_per_CDS <- rbind.data.frame(variants_per_gene[variants_per_gene$gene %in% CDS_size$gene,], data.frame(gene = setdiff(CDS_size$gene,variants_per_gene$gene), variant_count = 0))                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort and add CDS length as fraction of total CDS length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compare the number of variants we would expect by chance and the number of variants we actually observe. Some genes are so big that they’ll definitely have more of variants than NOTCH1. What’s significant is how many variants a gene has given its size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted <- variants_per_CDS[order(as.character(variants_per_CDS$gene)),]\n",
    "variants_per_CDS_withsizes <- data.frame(sorted,length_proportion=CDS_size$length_proportion)\n",
    "\n",
    "# Print out results to check\n",
    "variants_per_CDS_withsizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify genes where significantly more variants are observed than expected (Cluster.Test method)\n",
    "\n",
    "The method takes in two arguments: NbrInTarget and TargetProbability:\n",
    "\n",
    "* **NbrInTarget** is derived from our data and consists of a list of the number of variants (or hits) per each CDS.\n",
    "\n",
    "* **TargetProbability** is the fraction of the total human coding sequence represented by each gene coding sequence. (i.e. gene CDS size/total CDS size). This information is typically derived from BioMart but we can just provide it directly in a file in the Google bucket.\n",
    "\n",
    "Therefore:\n",
    "* N is the number of genes/gene CDS being tested\n",
    "* TotalHits is the total number of variants\n",
    "* ExpectedHits is the number of variants we expect to see in a gene CDS based on its size\n",
    "\n",
    "The last line applies multiple testing correction to the statistical method (i.e. N tests for N gene CDS).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster.Test <- function(NbrInTarget,TargetProbability){\n",
    "N <- length(NbrInTarget)\n",
    "TotalHits <- sum(NbrInTarget)\n",
    "ExpectedHits <- TotalHits*TargetProbability\n",
    "# N*ppois(NbrInTarget,ExpectedHits,lower=F)\n",
    "1-exp(ppois(NbrInTarget,ExpectedHits,lower=T,log=T)*N)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the output of the Cluster.Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdata <- data.frame(variants_per_CDS_withsizes, cluster.test.result = Cluster.Test(variants_per_CDS_withsizes$variant_count,variants_per_CDS_withsizes$length_proportion))\n",
    "newdata[order(newdata$cluster.test.result),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variant_counts <- head(newdata[order(newdata$cluster.test.result),],20)\n",
    "Variant_counts$minuslog10p = -log10(Variant_counts$cluster.test.result+1e-100)\n",
    "bars <- barplot(Variant_counts$minuslog10p,names.arg = Variant_counts$gene, las=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in particular the ranking of deleterious variants for the 500-sample cohort. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with original paper results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important to note is the difference between results when analyzing the synthetic cohorts of 100 and 500 participants. The results are presented side-by-side below:     \n",
    "\n",
    "4.1. First the original paper results alongside the results for the synthetic cohort of 100 participants \n",
    "\n",
    "4.2. The original paper results alongside the results for the synthetic cohort of 500 participants \n",
    "\n",
    "**To recap:**   \n",
    "Running the cluster analysis on the 100-sample synthetic cohort identifies NOTCH1 as an important (but not **the most important**) source of deleterious variants. \n",
    "\n",
    "Running the cluster analysis on the 500-sample synthetic cohort, on the other hand, reveals that NOTCH1 harbours **the highest excess of rare, deleterious variants among ToF patients**.  \n",
    "    \n",
    "The 500 cohort reproduces the results of the original paper, which was known for its large cohort size, demonstrating the importance of large numbers for statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original results versus the synthetic cohort of 100 participants \n",
    "\n",
    "| Original Analysis (cohort of 929) | Reproduced Analysis (synthetic cohort of 100 |    \n",
    "|-----------------------------------|----------------------------------------------|     \n",
    "| ![Original results from published paper](https://storage.cloud.google.com/terra-featured-workspaces/Reproducibility_Case_Study_Tetralogy_of_Fallot/ToF_Original_paper_cluster_analysis_results.png) | ![Reproduced_analysis_synthetic_cohort_of_100](https://storage.cloud.google.com/terra-featured-workspaces/Reproducibility_Case_Study_Tetralogy_of_Fallot/Synthetic_cohort_100_results_cluster_analysis_small.png) | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original results versus the synthetic cohort of 500 participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Original analysis results (cohort of 929) | Reproduced Analysis (synthetic cohort of 500) |    \n",
    "| ------------------------------------------|-----------------------------------------------|    \n",
    "| ![Original results from published paper](https://storage.cloud.google.com/terra-featured-workspaces/Reproducibility_Case_Study_Tetralogy_of_Fallot/ToF_Original_paper_cluster_analysis_results.png) | ![Reproduced_analysis_synthetic_cohort_of_500](https://storage.cloud.google.com/terra-featured-workspaces/Reproducibility_Case_Study_Tetralogy_of_Fallot/Synthetic_cohort_500_cluster_analysis_results_small.png)| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
